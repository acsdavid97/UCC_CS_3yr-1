{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Class, for use in pipelines, to select certain columns from a DataFrame and convert to a numpy array\n",
    "# From A. Geron: Hands-On Machine Learning with Scikit-Learn & TensorFlow, O'Reilly, 2017\n",
    "# Modified by Derek Bridge to allow for casting in the same ways as pandas.DataFrame.astype\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names, dtype=None):\n",
    "        self.attribute_names = attribute_names\n",
    "        self.dtype = dtype\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_selected = X[self.attribute_names]\n",
    "        if self.dtype:\n",
    "            return X_selected.astype(self.dtype).values\n",
    "        return X_selected.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define some functions to read the dataset from the files provided. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reads all files from the directory specified, and their content is returned as\n",
    "# a pandas Series of strings. \n",
    "def read_files_from_dir(directory):\n",
    "    files_contents = []\n",
    "    for file_name in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, file_name)\n",
    "        with open(file_path) as f:\n",
    "            files_contents.append(f.read())\n",
    "    return pd.Series(files_contents)\n",
    "\n",
    "# Converts a series to a dataframe and adds for each of the elements a \n",
    "# constant numeric label, specified in the parameter label. \n",
    "def to_pd_DF_with_label(ser, label):\n",
    "    df = pd.DataFrame()\n",
    "    df['text'] = ser\n",
    "    df['label'] = pd.Series(np.ones(len(df), dtype=np.int64) * label, index=df.index)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use the functions we defined, to actually read in the dataset.\n",
    "These lines of code assume that the spam and ham archives have been extracted to spam and ham directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read hams with label 0, since they are the negative class\n",
    "hams = to_pd_DF_with_label(read_files_from_dir('ham'), 0)\n",
    "# read spams with label 1, since they are the positive class\n",
    "spams = to_pd_DF_with_label(read_files_from_dir('spam'), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1650, 2)\n",
      "(1248, 2)\n"
     ]
    }
   ],
   "source": [
    "# check if we succeeded in reading in the dataset.\n",
    "print(hams.shape)\n",
    "print(spams.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have two separate dataframes, we should append one to the other, to have all data data in a single dataframe. After the append, we know that all hams are before all the spams, so we should shuffle the dataset to avoid problems with k-fold in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2898, 2)\n"
     ]
    }
   ],
   "source": [
    "emails = hams.append(spams, ignore_index=True)\n",
    "emails = emails.take(np.random.permutation(len(emails)))\n",
    "emails.reset_index(drop=True, inplace=True)\n",
    "print(emails.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening the email files we can see that the first lines of all the emails are data about the email itself (metadata). Since we do not want to conduct metadata analysis of the email, we can delete this metadata, leaving us with the title and the body of the email. \n",
    "In order to strip the metadata we have to identify it. After opening a few files, I noticed a pattern: the metadata is delimited by an empty line in the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails['stripped'] = emails['text'].str.replace(r'(.*?)\\n\\n', '', flags=re.MULTILINE | re.DOTALL, n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we got rid of the metadata, the next thing I think to be unnecessary is the data found between HTML tags, so we could remove those too, in order to remain with only the plain text of the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails['just_text'] = emails['stripped'].str.replace(r\"<(.*?)>\", '', flags=re.MULTILINE | re.DOTALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(stop_words='english')),\n",
    "    ('classifier', LogisticRegression()),\n",
    "])\n",
    "dummy_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(['label'])),\n",
    "    ('dummy', DummyClassifier(strategy='most_frequent')),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the labels\n",
    "y = emails['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how the dummy classifier performs, which will predict the most frequent class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56935926500417611"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(dummy_pipeline, emails, y, scoring='accuracy', cv=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the accuracy of the classifier, with 10-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97239470230282765"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(pipeline, emails['stripped'], y, scoring='accuracy', cv=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1602,   48],\n",
       "       [  32, 1216]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = cross_val_predict(pipeline, emails['stripped'], y, cv=10)\n",
    "confusion_matrix(y, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As you can observe, the classifier is not making too many false positives (ham classified as spam), the type of error we are trying to avoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
