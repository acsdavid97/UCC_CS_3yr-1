{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>CS4618: Artificial Intelligence I</h1>\n",
    "<h1>Error Estimation</h1>\n",
    "<h2>\n",
    "    Derek Bridge<br>\n",
    "    School of Computer Science and Information Technology<br>\n",
    "    University College Cork\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<h1>Initialization</h1>\n",
    "$\\newcommand{\\Set}[1]{\\{#1\\}}$ \n",
    "$\\newcommand{\\Tuple}[1]{\\langle#1\\rangle}$ \n",
    "$\\newcommand{\\v}[1]{\\pmb{#1}}$ \n",
    "$\\newcommand{\\cv}[1]{\\begin{bmatrix}#1\\end{bmatrix}}$ \n",
    "$\\newcommand{\\rv}[1]{[#1]}$ \n",
    "$\\DeclareMathOperator{\\argmax}{arg\\,max}$ \n",
    "$\\DeclareMathOperator{\\argmin}{arg\\,min}$ \n",
    "$\\DeclareMathOperator{\\dist}{dist}$\n",
    "$\\DeclareMathOperator{\\abs}{abs}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Class, for use in pipelines, to select certain columns from a DataFrame and convert to a numpy array\n",
    "# From A. Geron: Hands-On Machine Learning with Scikit-Learn & TensorFlow, O'Reilly, 2017\n",
    "# Modified by Derek Bridge to allow for casting in the same ways as pandas.DataFrame.astype\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names, dtype=None):\n",
    "        self.attribute_names = attribute_names\n",
    "        self.dtype = dtype\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_selected = X[self.attribute_names]\n",
    "        if self.dtype:\n",
    "            return X_selected.astype(self.dtype).values\n",
    "        return X_selected.values\n",
    "    \n",
    "# Class, for use in pipelines, to binarize nominal-valued features (while avoiding the dummy variabe trap)\n",
    "# By Derek Bridge, 2017\n",
    "class FeatureBinarizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features_values):\n",
    "        self.features_values = features_values\n",
    "        self.num_features = len(features_values)\n",
    "        self.labelencodings = [LabelEncoder().fit(feature_values) for feature_values in features_values]\n",
    "        self.onehotencoder = OneHotEncoder(sparse=False,\n",
    "            n_values=[len(feature_values) for feature_values in features_values])\n",
    "        self.last_indexes = np.cumsum([len(feature_values) - 1 for feature_values in self.features_values])\n",
    "    def fit(self, X, y=None):\n",
    "        for i in range(0, self.num_features):\n",
    "            X[:, i] = self.labelencodings[i].transform(X[:, i])\n",
    "        return self.onehotencoder.fit(X)\n",
    "    def transform(self, X, y=None):\n",
    "        for i in range(0, self.num_features):\n",
    "            X[:, i] = self.labelencodings[i].transform(X[:, i])\n",
    "        onehotencoded = self.onehotencoder.transform(X)\n",
    "        return np.delete(onehotencoded, self.last_indexes, axis=1)\n",
    "    def fit_transform(self, X, y=None):\n",
    "        onehotencoded = self.fit(X).transform(X)\n",
    "        return np.delete(onehotencoded, self.last_indexes, axis=1)\n",
    "    def get_params(self, deep=True):\n",
    "        return {\"features_values\" : self.features_values}\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            self.setattr(parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use pandas to read the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"datasets/dataset_corkA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The features we want to select\n",
    "numeric_features = [\"flarea\", \"bdrms\", \"bthrms\", \"floors\"]\n",
    "nominal_features = [\"type\", \"devment\", \"ber\", \"location\"]\n",
    "\n",
    "# Create the pipelines\n",
    "numeric_pipeline = Pipeline([\n",
    "        (\"selector\", DataFrameSelector(numeric_features))\n",
    "    ])\n",
    "\n",
    "nominal_pipeline = Pipeline([\n",
    "        (\"selector\", DataFrameSelector(nominal_features)), \n",
    "        (\"binarizer\", FeatureBinarizer([df[feature].unique() for feature in nominal_features]))])\n",
    "\n",
    "pipeline = Pipeline([(\"union\", FeatureUnion([(\"numeric_pipeline\", numeric_pipeline), \n",
    "                                             (\"nominal_pipeline\", nominal_pipeline)]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the estimator\n",
    "linreg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the target values\n",
    "y = df[\"price\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run the pipeline to prepare the data\n",
    "pipeline.fit(df)\n",
    "X = pipeline.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the linear model\n",
    "linreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>How Good Is This Model?</h1>\n",
    "<ul>\n",
    "    <li>We've built an estimator by learning a model from a dataset</li>\n",
    "    <li>We want to know how well it will do in practice, once we start to use it to make predictions\n",
    "        <ul>\n",
    "            <li>This is called <b>error estimation</b></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Easy right? \n",
    "        <ul>\n",
    "            <li>The dataset comes with <em>actual</em> target values</li>\n",
    "            <li>We can ask the estimator to <em>predict</em> target values for each example in the dataset</li>\n",
    "            <li>So now we have actual and predicted values, we can compute the mean squared error</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted = linreg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3924.7640981932445"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>But, for at least two reasons, we don't do this!\n",
    "        <ul>\n",
    "            <li>We might want to use a different performance measure than what we used as the loss function</li>\n",
    "            <li>We want to know how well the model <b>generalizes</b> to <b>unseen data</b></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Choosing a Different Performance Measure</h1>\n",
    "<ul>\n",
    "    <li>Often in machine learning, we use one measure during learning and another for evaluation</li>\n",
    "    <li>Class exercise: We already saw this with $k$-means clustering. Explain!</li>\n",
    "    <li>Our loss function (mean squared error or half of it!) was ideal for learning (why?)\n",
    "        but may not be so good as a performance measure\n",
    "        <ul>\n",
    "            <li>We could use <b>root mean squared error</b> (RMSE):\n",
    "                $$\\sqrt{\\frac{1}{m}\\sum_{i=1}^m(h_{\\v{\\beta}}(\\v{x}^{(i)}) - \\v{y}^{(i)})^2}$$\n",
    "                (i.e don't halve the MSE, and take its square root: it's the standard deviation\n",
    "                of the errors in the predictions)\n",
    "            </li>\n",
    "            <li>We could use <b>mean absolute error</b> (MAE):\n",
    "                $$\\frac{1}{m}\\sum_{i=1}^m\\abs(h_{\\v{\\beta}}(\\v{x}^{i)}) - \\v{y}^{(i)})$$\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    " </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.638396337007784"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Generalizing to Unseen Data</h1>\n",
    "<ul>\n",
    "    <li>The error on the training set is called the <b>training error</b>\n",
    "        (also 'resubstitution error' and 'in-sample error')\n",
    "    </li>\n",
    "    <li>But we want to know how well we will perform in the future, on <em>unseen data</em>\n",
    "        <ul>\n",
    "            <li>The training error is not, in general a good indicator of performance on unseen data</li>\n",
    "            <li>It's often too optimistic. Why?</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>To predict future performance, we need to measure error on an <em>independent</em> dataset\n",
    "        <ul>\n",
    "            <li>A dataset that played no part in creating the estimator</li>\n",
    "            <li>This second dataset is called the <b>test set</b></li>\n",
    "            <li>The error on the test set is called the <b>test error</b> (also 'out-of-sample error' and\n",
    "                'extra-sample error')\n",
    "            </li>\n",
    "       </ul>\n",
    "   </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Holdout</h1>\n",
    "<ul>\n",
    "    <li>So we use the following method:\n",
    "       <ul>\n",
    "           <li><em>Partition</em> our dataset at random into two:\n",
    "               <ul>\n",
    "                   <li>training set (e.g. 80% of the full dataset)</li>\n",
    "                   <li>test set (the rest of the full dataset)</li>\n",
    "                </ul>\n",
    "           </li>\n",
    "           <li>Train the estimator on the training set</li>\n",
    "           <li>Test the model (evaluate the predictions) on the test set</li>\n",
    "       </ul>\n",
    "   </li>\n",
    "   <li>\n",
    "       This method is called the <b>holdout</b> method, because the test set\n",
    "       is withheld (held-out) during training\n",
    "       <ul>\n",
    "           <li>It is essential that the test set is not used in any way to create\n",
    "               the estimator\n",
    "           </li>\n",
    "           <li><em>Don't even look at it!</em>\n",
    "           </li>\n",
    "           <li>'Cheating' is called <b>leakage</b></li>\n",
    "           <li>'Cheating' is one cause of <b>overfitting</b> (see <i>CS4619</i>)</li>\n",
    "       </ul>\n",
    "    </li>\n",
    "    <li>Class exercise: Standardization, as we know, is about scaling the data. It requires calculation\n",
    "        of the mean and standard deviation. When should the mean and standard deviation be calculated:\n",
    "        (a) before splitting, on the entire dataset, or (b) after splitting, on just the training set?\n",
    "        Why?\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Holdout in scikit-learn</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use pandas to read the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"datasets/dataset_corkA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The features we want to select\n",
    "numeric_features = [\"flarea\", \"bdrms\", \"bthrms\", \"floors\"]\n",
    "nominal_features = [\"type\", \"devment\", \"ber\", \"location\"]\n",
    "\n",
    "# Create the pipelines\n",
    "numeric_pipeline = Pipeline([\n",
    "        (\"selector\", DataFrameSelector(numeric_features))\n",
    "    ])\n",
    "\n",
    "nominal_pipeline = Pipeline([\n",
    "        (\"selector\", DataFrameSelector(nominal_features)), \n",
    "        (\"binarizer\", FeatureBinarizer([df[feature].unique() for feature in nominal_features]))])\n",
    "\n",
    "pipeline = Pipeline([(\"union\", FeatureUnion([(\"numeric_pipeline\", numeric_pipeline), \n",
    "                                             (\"nominal_pipeline\", nominal_pipeline)])),\n",
    "                     (\"estimator\", LinearRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the target values\n",
    "y = df[\"price\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the object that splits the data\n",
    "ss = ShuffleSplit(n_splits=1, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-51.65689577])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the pipeline\n",
    "cross_val_score(pipeline, df, y, scoring=\"neg_mean_absolute_error\", cv=ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>This is the negative of the MAE &mdash; so that higher values (closer to zero ) are better</li>\n",
    "    <li>Compare this value to what we got earlier, when we were training and testing on the whole dataset</li>\n",
    "    <li>Run it again: what do you notice?</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Pipelines Explained</h1>\n",
    "<ul>\n",
    "    <li>We are finally in a better position to explain pipelines in scikit-learn</li>\n",
    "    <li>A scikit-learn pipeline contains a number of steps\n",
    "    <li>All the steps except the last one must be <b>transformers</b>:\n",
    "        <ul>\n",
    "            <li>They are used to transform the data, e.g. to scale it; to binarize it; \n",
    "                to reduce its dimensions; &hellip;\n",
    "            </li>\n",
    "            <li>They have a method called <code>fit</code>, which computes any values needed to carry\n",
    "                out the transformation\n",
    "                <ul>\n",
    "                    <li>E.g. what does the <code>fit</code> method of <code>StandardScaler</code> compute?\n",
    "                    </li>\n",
    "                    <li>E.g. what about <code>MinMaxScaler</code>? <code>PCA</code>?\n",
    "                    </li>\n",
    "                </ul>\n",
    "            </li>\n",
    "            <li>They have a method called <code>transform</code>, which uses the values computed by \n",
    "                <code>fit</code> to modify whatever data is passed to it\n",
    "                <ul>\n",
    "                    <li>E.g what does the <code>transform</code> method of <code>StandardScaler</code>\n",
    "                        do?\n",
    "                    </li>\n",
    "                    <li>What about <code>MinMaxScaler</code>? <code>PCA</code>?\n",
    "                    </li>\n",
    "                </ul>\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>The last step in a pipeline can be an <b>estimator</b>:\n",
    "        <ul>\n",
    "            <li>They are used to build models from the data and make predictions\n",
    "                (typically regression and classification)\n",
    "            </li>\n",
    "            <li>They have a method called <code>fit</code> which learns the model from the data\n",
    "                <ul>\n",
    "                    <li>E.g. what does the <code>fit</code> method of <code>LinearRegression</code> do?\n",
    "                    </li>\n",
    "                </ul>\n",
    "            </li>\n",
    "            <li>They have a method called <code>predict</code>, which uses the model learned by the\n",
    "                <code>fit</code> method to make predictions\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Pipelines themselves have various methods including:\n",
    "        <ul>\n",
    "            <li><code>fit</code>: this calls the <code>fit</code> method of the first step, then its\n",
    "                <code>transform</code> method; then the <code>fit</code> method of the second step,\n",
    "                then its <code>transform</code> method; and so on; and, eventually, if the last step is\n",
    "                an estimator, it calls the <code>fit</code> method of the estimator\n",
    "            </li>\n",
    "            <li><code>predict</code>: this calls the <code>transform</code> method of the first step;\n",
    "                then the <code>transform</code> method of the second step; and so on; and, eventually, if the\n",
    "                last step is an estimator, it calls the <code>predict</code> method of the estimator\n",
    "            </li>\n",
    "        </ul>\n",
    "        Hence it makes sense:\n",
    "        <ul>\n",
    "            <li>to call the pipeline's <code>fit</code> method on the <em>training set</em></li>\n",
    "            <li>then to call the pipeline's <code>predict</code> method on the <em>test set</em></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Pipelines Explained, continued</h1>\n",
    "<ul>\n",
    "    <li>You pass your training set into a pipeline's <code>fit</code> method:\n",
    "        <figure>\n",
    "            <img src=\"images/17_pipeline1.png\" />\n",
    "        </figure>\n",
    "    </li>\n",
    "    <li>Then, you pass your test data into a pipeline's <code>predict</code> method: \n",
    "        <figure>\n",
    "            <img src=\"images/17_pipeline2.png\" />\n",
    "        </figure>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><code>cross_val_score</code> explained</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-59.31289355])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the object that splits the data\n",
    "ss = ShuffleSplit(n_splits=1, train_size=0.8)\n",
    "\n",
    "# Run the pipeline\n",
    "cross_val_score(pipeline, df, y, scoring=\"neg_mean_absolute_error\", cv=ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li><code>cross_val_score</code> takes in the full dataset and the target values</li>\n",
    "    <li>It splits the dataset in a way determined by its <code>cv</code> parameter</li>\n",
    "    <li>It calls the pipeline's <code>fit</code> method on the training set</li>\n",
    "    <li>It calls the pipeline's <code>predict</code> method on the test set</li>\n",
    "    <li>It compares the test set's actual target values with the test set's predictions using the\n",
    "        scoring function\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Pros and Cons of Holdout</h1>\n",
    "<ul>\n",
    "    <li>The advantage of holdout is:\n",
    "        <ul>\n",
    "            <li>The test error is independent of the training set</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>The disadvantages of this method are:\n",
    "        <ul>\n",
    "            <li>Results can vary quite a lot across different runs\n",
    "                <ul>\n",
    "                    <li>Informally, you might get lucky &mdash; or unlucky</li>\n",
    "                </ul>\n",
    "                I.e. in any one split, the data used for training or testing might not be representative\n",
    "            </li>\n",
    "            <li>We are training on only a subset of the available dataset, perhaps as little as 50% of it\n",
    "                <ul>\n",
    "                    <li>From so little data, we may learn a worse model and so our error measurement may \n",
    "                        be pessimistic\n",
    "                    </li>\n",
    "                </ul>\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>In practice, we only use the holdout method when we have a very large dataset \n",
    "        <ul>\n",
    "            <li>The size  of the dataset mitigates the above problems</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "        When we have a smaller dataset, we use a <b>resampling</b> method:\n",
    "        <ul>\n",
    "            <li>The examples get re-used for training and testing</li>\n",
    "        </ul>\n",
    "    </li> \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>$k$-Fold Cross-Validation</h1>\n",
    "<ul>\n",
    "    <li>The most-used resampling method is $k$-fold cross-validation:\n",
    "        <ul>\n",
    "            <li>We randomly partition the data into $k$ disjoint subsets of equal size\n",
    "                <ul>\n",
    "                    <li>Each of the partitions is called a <b>fold</b></li>\n",
    "                    <li>Typically, $k = 10$, so you have 10 folds</li>\n",
    "                    <li>But, for conventional statistical significance testing to be applicable, you should probably ensure \n",
    "                        that the number of examples in each fold does not fall below 30. (If this isn't possible, then either \n",
    "                        use a smaller value for $k$, or do not use $k$-fold cross validation!)\n",
    "                    </li>\n",
    "                </ul>\n",
    "            </li>\n",
    "            <li>You take each fold in turn and use it as the test set, training the learner on \n",
    "                the remaining folds\n",
    "            </li>\n",
    "            <li>Clearly, you can do this $k$ times, so that each fold gets 'a turn' at being the test set\n",
    "                <ul>\n",
    "                    <li>\n",
    "                        By this method, each example is used exactly once for testing, and $k - 1$ times for training\n",
    "                    </li>\n",
    "                </ul>\n",
    "            </li>\n",
    "        </ul>\n",
    "    <li>In pseudocode:\n",
    "        <ul style=\"background: lightgray; list-style: none\">\n",
    "            <li>\n",
    "                partition the dataset $D$ into $k$ disjoint equal-sized subsets, $T_1, T_2,\\ldots,T_k$\n",
    "            <li>\n",
    "            <li>\n",
    "                <b>for</b> $i = 1$ to $k$\n",
    "                <ul>\n",
    "                    <li>train on $D \\setminus T_i$</li>\n",
    "                    <li>make predictions for $T_i$</li>\n",
    "                    <li>measure error (e.g. MAE)</li>\n",
    "                </ul>\n",
    "                report the mean of the errors\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Pros and Cons of $k$-Fold Cross-Validation</h2>\n",
    "<ul>\n",
    "    <li>Pros:\n",
    "        <ul>\n",
    "            <li>\n",
    "                The test errors of the folds are independent &mdash; because examples are included in only one test set\n",
    "            </li>\n",
    "            <li>\n",
    "                Better use is made of the dataset: for $k = 10$, for example, we train using 9/10 of the dataset\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Cons:\n",
    "        <ul>\n",
    "            <li>\n",
    "                While the test sets are independent of each other, the training sets are not: \n",
    "                <ul>\n",
    "                    <li>They will overlap with each other to some degree</li>\n",
    "                    <li>(This effect of this will be less, of course, for larger datasets)</li>\n",
    "                </ul>\n",
    "            </li>\n",
    "            <li>\n",
    "                The number of folds is constrained by the size of the dataset and the desire to have folds of\n",
    "                at least 30 examples\n",
    "            </li>\n",
    "            <li>\n",
    "                It can be costly to train the learning algorithm $k$ times\n",
    "            </li>\n",
    "            <li>\n",
    "                There may still be some variability in the results due to 'lucky'/'unlucky' splits \n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>$k$-Fold Cross Validation in scikit-learn</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-59.428212082117433"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the object that splits the data\n",
    "kf = KFold(n_splits = 10)\n",
    "\n",
    "# Run the pipeline\n",
    "np.mean(cross_val_score(pipeline, df, y, scoring=\"neg_mean_absolute_error\", cv=kf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>But $k$-fold cross-validation is so common, there's a shorthand:</li>\n",
    "</ul>   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-59.428212082117433"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(pipeline, df, y, scoring=\"neg_mean_absolute_error\", cv=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Be warned, however, this almost certainly does not shuffle the dataset before splitting it into folds\n",
    "        <ul>\n",
    "            <li>Why might that be a problem?</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "        You should probably shuffle the <code>DataFrame</code> just after reading it in from the CSV file \n",
    "        (see example below)\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Final Remarks</h1>\n",
    "<ul>\n",
    "    <li>\n",
    "        There are many resampling methods other than $k$-Fold Cross-Validation:\n",
    "        <ul>\n",
    "            <li>Repeated $k$-Fold Cross-Validation, Leave-One-Out-Cross-Validation, \n",
    "                &hellip;\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "        So you've used one of the above methods and found the test error of your estimator.\n",
    "        <ul>\n",
    "            <li>This is supposed to give you an idea of how your estimator will perform in practice</li>\n",
    "            <li>What if you are dissatisfied with the test error? It seems too high\n",
    "                <ul>\n",
    "                    <li>It is tempting to tweak your learning algorithm or try different algorithms\n",
    "                        to try to bring down the test error\n",
    "                    </li>\n",
    "                    <li>This is wrong! It is <b>leakage</b> again: you will be using knowledge of the test \n",
    "                        set to develop the estimator and is likely to result in an optimistic view of the \n",
    "                        ultimate performance of the estimator on unseen data\n",
    "                    </li>\n",
    "                    <li>Ideally, error estimation on the test set is the last thing you do\n",
    "                </ul>\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "        Finally, suppose you have used one of the above methods to estimate the error of your regressor. \n",
    "        You are ready to release your regressor on the world. At this point, you can train it on\n",
    "        <em>all</em> the examples in your dataset, so as to maximize the use of the data\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>A Little Case Study in scikit-learn</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use pandas to read the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"datasets/dataset_corkA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shuffle\n",
    "df = df.take(np.random.permutation(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The features we want to select\n",
    "numeric_features = [\"flarea\", \"bdrms\", \"bthrms\", \"floors\"]\n",
    "nominal_features = [\"type\", \"devment\", \"ber\", \"location\"]\n",
    "\n",
    "# Create the pipelines\n",
    "numeric_pipeline = Pipeline([\n",
    "        (\"selector\", DataFrameSelector(numeric_features)),\n",
    "    ])\n",
    "\n",
    "numeric_pipeline_with_PCA = Pipeline([\n",
    "        (\"selector\", DataFrameSelector(numeric_features)),\n",
    "        (\"pca\", PCA(n_components=0.9))\n",
    "    ])\n",
    "\n",
    "nominal_pipeline = Pipeline([\n",
    "        (\"selector\", DataFrameSelector(nominal_features)), \n",
    "        (\"binarizer\", FeatureBinarizer([df[feature].unique() for feature in nominal_features]))])\n",
    "\n",
    "pipeline = Pipeline([(\"union\", FeatureUnion([(\"numeric_pipeline\", numeric_pipeline), \n",
    "                                             (\"nominal_pipeline\", nominal_pipeline)])),\n",
    "                         (\"estimator\", LinearRegression())])\n",
    "\n",
    "pipeline_with_PCA = Pipeline([(\"union\", FeatureUnion([(\"numeric_pipeline\", numeric_pipeline_with_PCA), \n",
    "                                                      (\"nominal_pipeline\", nominal_pipeline)])),\n",
    "                              (\"estimator\", LinearRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the target values\n",
    "y = df[\"price\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-57.493916350809968"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the no-PCA pipeline\n",
    "np.mean(cross_val_score(pipeline, df, y, scoring=\"neg_mean_absolute_error\", cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-57.457440456251007"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the pipeline with PCA\n",
    "np.mean(cross_val_score(pipeline_with_PCA, df, y, scoring=\"neg_mean_absolute_error\", cv=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<ul>\n",
    "    <li>Final observation: In the above, we ran 10-fold cross validation on the Cork property dataset but it has \n",
    "        only 224 examples &mdash; not enough examples to give at least 30 examples in each of the 10 folds\n",
    "    </li>\n",
    "    <li>So this isn't an ideal use of the method</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
